{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppsett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['font.size'] = 16.0\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer data\n",
    "\n",
    "Datasettet har 28480 rader og 30 kolonner (hvorav én er label).\n",
    "\n",
    "Det første vi gjør er å importere datasettet og splitte attributtene fra klassen til en **X**-matrise og **y**-vektor.\n",
    "\n",
    "**X** er allerede skalert med `sklearn.metrics.scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename):\n",
    "    cc = pd.read_csv(\"data/\" + filename)\n",
    "    X = cc.drop(\"Class\", axis=1)\n",
    "    y = cc[\"Class\"]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = read_dataset(\"cc_scaled_small.csv\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vet ikke hva attributtene betyr, så vi får bare håpe på det beste!\n",
    "\n",
    "Splitt opp datasettet i treningsdata og testdata og tren en modell. Vi bruker her en `Random Forest`, som bruker en samling tilfeldige Decision Trees for å ta avgjørelser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1337, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1: Accuracy\n",
    "\n",
    "Vi har nå modellens antakelse i `y_pred` og de faktiske klassene i `y_test`.\n",
    "\n",
    "Finn modellens nøyaktighet (accuracy).\n",
    "\n",
    "PS: Dette er veldig overkommelig å gjøre for hånd, men du kan også bruke `sklearn.metrics.accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ble resultatet som forventet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 2: Null Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finn frekvensen til den vanligste klassen (\"Ikke svindel\" = 0).\n",
    "\n",
    "PS: `sklearn.dummy.DummyClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hva sier dette om resultatet i Oppgave 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 3: Confusion Matrix\n",
    "\n",
    "Få et bedre overblikk over hvordan modellen gjorde det ved å plotte en confusion matrix for evalueringen.\n",
    "\n",
    "Funksjonen under lar deg plotte en confusion matrix på en visuelt forståelig måte. Sleng med `normalize=True` for å få relative tall (per rad == klasse).\n",
    "\n",
    "Det viktige her er å få en confusion matrix du forstår, så dersom funksjonen under ikke fungerer for deg er det bare å finne en annen måte å gjøre det på!\n",
    "\n",
    "PS: `sklearn.metrics.confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "import itertools\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    classes = [\"Ikke svindel\", \"Svindel\"]\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes, rotation=45)\n",
    "\n",
    "    fmt = '.4f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Faktisk klasse')\n",
    "    plt.xlabel('Antatt klasse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvilke tall er de viktigste her?\n",
    "\n",
    "Hvorfor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 4: F-measure\n",
    "\n",
    "Finn modellens Precision, Recall og F1-score.\n",
    "\n",
    "PS: Fortsatt `sklearn.metrics`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvilket av disse målene er nyttigst?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 5: AUROC\n",
    "\n",
    "Regn ut Area Under ROC\n",
    "\n",
    "PS: `sklearn.metrics.roc_auc_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hva sier dette om `recall` vi fant tidligere? Kan den forbedres uten videre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 6: Cross-validation\n",
    "\n",
    "Evaluer modellen med cross-validated recall og undersøk hvor bra modellen gjorde det i hver iterasjon.\n",
    "\n",
    "PS: `sklearn.model_selection.cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, score in enumerate(scores):\n",
    "    print \"Iterasjon {}: {:.4f}\".format(i, scores[i])\n",
    "\n",
    "\n",
    "print \"\\nSnitt: {:.4f}\".format(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merk hvor varierende modellen gjør det; Hvordan vi splitter kan altså ha mye å si for resultatet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Oppgave 7: Hyperparameter Optimization\n",
    "\n",
    "Finn en bedre modell ved å initialisere modellen med forskjellige verdier før trening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = { 'n_estimators': range(5, 100)\n",
    "         , 'criterion': [\"gini\", \"entropy\"]\n",
    "         , 'min_samples_split': range(2, 11)\n",
    "         , 'min_samples_leaf': range(1, 11)\n",
    "         , 'max_features': ['sqrt', 'log2'] + range(1, 29)\n",
    "         , 'max_depth': range(1, 100)\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Husk at hele treningsløpet må skje fra bunn hver gang du evaluerer for å forsøke å unngå bias. Du klarer ca. 20 skoger per minutt (hvis du benytter alle kjernene du har), så ikke vær for ambisiøs!\n",
    "\n",
    "PS: Se på `sklearn.model_selection.GridSearchCV` og `sklearn.model_selection.RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 8: Valider på hold-out\n",
    "\n",
    "Sjekk hvordan den beste modellen du fant i oppgave 7 gjør det på et annet datasett.\n",
    "\n",
    "`cc_scaled_holdout.csv` er 9 ganger større, så i en realistisk situasjon ville vi trent på litt mer og brukt den ferdigtrente modellen på holdout til slutt. Her kan du sjekke hva du får ved cross-validation av modellen din på hele holdout-settet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX, yy = read_dataset(\"cc_scaled_holdout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er dette noe bedre enn en \"dum\" (uoptimert) Random Forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
